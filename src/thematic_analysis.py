import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import logging
import spacy # Already imported in preprocessing, but good to ensure here if run independently

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Load SpaCy model for tokenization and lemmatization (already in preprocessing, but for standalone run)
nlp = None
try:
    nlp = spacy.load("en_core_web_sm")
    logging.info("SpaCy model 'en_core_web_sm' loaded successfully for thematic analysis.")
except Exception as e:
    logging.error(f"Error loading SpaCy model in thematic analysis: {e}. Please ensure 'python -m spacy download en_core_web_sm' has been run.")


# Moved tokenize_and_lemmatize to preprocessing.py as it's a preprocessing step.
# For thematic analysis, we will use the 'processed_text' column generated by preprocessing.

def extract_keywords_tfidf(df: pd.DataFrame, text_column: str = 'processed_text', top_n: int = 100) -> list:
    """
    Extracts top keywords using TF-IDF from the processed text column.

    Args:
        df (pd.DataFrame): DataFrame with a text column.
        text_column (str): Name of the column containing processed review text.
        top_n (int): Number of top keywords to extract.

    Returns:
        list: List of top keywords.
    """
    if df.empty or text_column not in df.columns:
        logging.warning("Input DataFrame for keyword extraction is empty or missing text column.")
        return []

    logging.info("Extracting keywords using TF-IDF...")
    # Ensure text_column has no missing values and is string type
    corpus = df[text_column].fillna("").astype(str).tolist()

    # Min_df can filter out very rare words, max_df can filter out very common words.
    # ngram_range=(1, 2) includes single words and two-word phrases.
    vectorizer = TfidfVectorizer(max_df=0.85, min_df=5, ngram_range=(1, 2))
    try:
        tfidf_matrix = vectorizer.fit_transform(corpus)
        feature_names = vectorizer.get_feature_names_out()

        # Get average TF-IDF score for each feature
        # Convert to a dense array for easier manipulation if memory allows, or keep sparse.
        avg_tfidf_scores = tfidf_matrix.mean(axis=0).A1 # .A1 converts to 1D numpy array
        sorted_indices = avg_tfidf_scores.argsort()[::-1] # Sort in descending order

        top_keywords = [feature_names[i] for i in sorted_indices[:top_n]]
        logging.info(f"Top {len(top_keywords)} keywords extracted.")
    except ValueError as e:
        logging.warning(f"Could not extract keywords (e.g., all docs too short, or no terms left after filtering): {e}")
        top_keywords = []
    return top_keywords

def assign_themes(df: pd.DataFrame, extracted_keywords: list, text_column: str = 'review_text') -> pd.DataFrame:
    """
    Assigns themes to reviews based on keyword presence. This is a rule-based
    approach using a predefined mapping of keywords to themes.

    Args:
        df (pd.DataFrame): DataFrame with 'review_text' column.
        extracted_keywords (list): List of keywords from TF-IDF or other methods.
                                   Used for informing theme definition, though not directly in matching.
        text_column (str): Name of the column containing the review text (original, not processed for matching).

    Returns:
        pd.DataFrame: DataFrame with 'identified_themes' column.
    """
    if df.empty or text_column not in df.columns:
        logging.warning("Input DataFrame for theme assignment is empty or missing text column.")
        return df

    logging.info("Assigning themes to reviews...")

    # Define your themes and associated keywords/phrases.
    # THIS IS THE MOST IMPORTANT PART FOR THEMATIC ANALYSIS.
    # You MUST review the `extracted_keywords` and negative/positive reviews
    # to define these mappings accurately for your specific data.
    # This example is a starting point based on general banking app issues.
    theme_keywords = {
        'Account Access Issues': ['login', 'log in', 'password', 'face id', 'fingerprint', 'access', 'unable to login', 'locked out', 'authenticate', 'verify', 'otp'],
        'Transaction Performance': ['transfer', 'slow', 'fast', 'transaction', 'payment', 'send money', 'receive money', 'load', 'loading', 'delay', 'otp', 'pending', 'processed'],
        'User Interface & Experience': ['ui', 'interface', 'design', 'easy to use', 'confusing', 'UX', 'navigation', 'friendly', 'layout', 'bug', 'crash', 'glitch', 'freezing', 'update'],
        'Customer Support': ['support', 'customer service', 'help', 'response', 'contact', 'call', 'chat', 'representative', 'agent', 'resolve', 'issue'],
        'Feature Requests': ['feature', 'add', 'option', 'dark mode', 'budgeting', 'new feature', 'request', 'wish', 'enable', 'tool'],
        'Security Concerns': ['security', 'safe', 'secure', 'fraud', 'phishing', 'data', 'privacy', 'vulnerable']
    }

    # Initialize identified_themes column with empty string or 'Other'
    df['identified_themes'] = ''

    for index, row in df.iterrows():
        review_text_lower = row[text_column].lower()
        themes_found = []
        for theme, kws in theme_keywords.items():
            if any(keyword in review_text_lower for keyword in kws):
                themes_found.append(theme)
        
        if themes_found:
            df.at[index, 'identified_themes'] = ', '.join(themes_found)
        else:
            df.at[index, 'identified_themes'] = 'Other' # Default theme if no specific keywords match

    # KPI Check: At least 3 themes identified per bank (this is an aggregated KPI, check in main.py or insights)
    # For now, ensure themes are assigned to each review.
    
    logging.info("Theme assignment complete.")
    return df

if __name__ == "__main__":
    print("Running thematic analysis module directly (for testing/debugging)...")
    # Need to import tokenize_and_lemmatize if running directly
    from src.preprocessing import tokenize_and_lemmatize
    from datetime import date

    dummy_data = {
        'review_text': [
            "Login is super slow, crashes frequently. Bad app.",
            "Fast transfer but UI is confusing. Needs update.",
            "Great app, customer support is very responsive.",
            "Can't access my account, password reset not working.",
            "I wish they would add a budgeting feature.",
            "This app is very secure and easy to use.",
            "My transactions are pending for days, horrible service.",
            "The dark mode feature would be awesome."
        ],
        'rating': [1, 3, 5, 1, 4, 5, 2, 4],
        'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08'],
        'bank': ['Bank A', 'Bank B', 'Bank A', 'Bank C', 'Bank A', 'Bank B', 'Bank C', 'Bank A'],
        'reviewId': ['t1','t2','t3','t4','t5','t6','t7','t8'],
        'userName': ['U1', 'U2', 'U3', 'U4', 'U5', 'U6', 'U7', 'U8'],
        'appVersion': ['1.0', '1.2', '1.0', '1.1', '1.0', '1.3', '1.1', '1.0'],
        'source': ['Google Play Store'] * 8
    }
    dummy_df = pd.DataFrame(dummy_data)
    
    # Apply tokenization/lemmatization for better keyword extraction
    dummy_df['processed_text'] = dummy_df['review_text'].apply(tokenize_and_lemmatize)
    
    top_keywords = extract_keywords_tfidf(dummy_df, text_column='processed_text', top_n=20)
    print("\nTop Keywords:", top_keywords)

    themed_df = assign_themes(dummy_df, top_keywords, text_column='review_text') # Use original review_text for theme matching
    print("\nDataFrame with identified themes:")
    print(themed_df[['review_text', 'identified_themes']].to_string())

    # KPI check for themes per bank (can be done here for demo)
    print("\nChecking KPI: Themes per Bank")
    for bank in themed_df['bank'].unique():
        bank_themes = themed_df[themed_df['bank'] == bank]['identified_themes'].str.split(', ').explode().dropna().unique()
        num_themes = len([t for t in bank_themes if t != 'Other'])
        print(f"Bank: {bank}, Themes identified (excluding 'Other'): {num_themes}")
        if num_themes >= 3:
            print(f"  KPI met for {bank}: {num_themes} themes found.")
        else:
            print(f"  KPI NOT met for {bank}: Only {num_themes} themes found (less than 3).")